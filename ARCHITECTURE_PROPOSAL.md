# ğŸ—ï¸ Arquitectura Propuesta: ClasificaciÃ³n de Aves Piciformes

## ğŸ“Š AnÃ¡lisis del Dataset

- **Total de imÃ¡genes**: 1,844
- **12 especies oficiales**: 140 imÃ¡genes cada una (1,680 total)
- **1 clase "no_oficiales"**: 164 imÃ¡genes
- **Balance**: Relativamente balanceado (variaciÃ³n ~15%)
- **DivisiÃ³n propuesta**: Train (70%) / Val (15%) / Test (15%)

## ğŸ¯ Objetivos del Proyecto

1. **ClasificaciÃ³n multiclase** de 13 clases (12 especies + "no_oficiales")
2. **Robustez** ante variaciones en poses, iluminaciÃ³n, fondos
3. **GeneralizaciÃ³n** para la clase "no_oficiales" (mÃºltiples especies agrupadas)
4. **MÃ©tricas de evaluaciÃ³n** comprehensivas y anÃ¡lisis de errores

---

## ğŸ›ï¸ Arquitectura Propuesta (Mejorada)

### **OpciÃ³n 1: Ensemble de Modelos Pre-entrenados** â­ (RECOMENDADA)

**JustificaciÃ³n**: Para un proyecto final robusto, un ensemble mejora la generalizaciÃ³n y reduce overfitting.

#### Modelo A: EfficientNet-B3
```
EfficientNet-B3 (pre-entrenado ImageNet)
    â†“
Global Average Pooling
    â†“
Dense(512) + BatchNorm + ReLU
    â†“
Dropout(0.5)
    â†“
Dense(256) + BatchNorm + ReLU
    â†“
Dropout(0.3)
    â†“
Dense(13) + Softmax
```

#### Modelo B: ResNet50
```
ResNet50 (pre-entrenado ImageNet)
    â†“
Global Average Pooling
    â†“
Dense(512) + BatchNorm + ReLU
    â†“
Dropout(0.5)
    â†“
Dense(256) + BatchNorm + ReLU
    â†“
Dropout(0.3)
    â†“
Dense(13) + Softmax
```

#### Modelo C: Vision Transformer (ViT-Base/16)
```
ViT-Base/16 (pre-entrenado ImageNet-21k)
    â†“
Classification Head
    â†“
Dense(512) + LayerNorm + GELU
    â†“
Dropout(0.5)
    â†“
Dense(13) + Softmax
```

#### **Ensemble Final**:
- **MÃ©todo**: Promedio ponderado de probabilidades (soft voting)
- **Pesos**: Optimizados en validaciÃ³n (ej: EfficientNet 0.4, ResNet50 0.35, ViT 0.25)
- **Ventaja**: Reduce errores individuales, mejora robustez

---

### **OpciÃ³n 2: Single Model Optimizado** (Alternativa mÃ¡s simple)

**EfficientNet-B2** (balance entre precisiÃ³n y velocidad):
```
EfficientNet-B2 (pre-entrenado)
    â†“
Global Average Pooling
    â†“
Dense(512) + BatchNorm + ReLU
    â†“
Dropout(0.5)
    â†“
Dense(256) + BatchNorm + ReLU
    â†“
Dropout(0.3)
    â†“
Dense(13) + Softmax
```

---

## ğŸ”§ ConfiguraciÃ³n de Entrenamiento

### **HiperparÃ¡metros Base**:
- **Optimizador**: AdamW (mejor que Adam para regularizaciÃ³n)
- **Learning Rate**: 
  - Inicial: 1e-4
  - Schedule: Cosine Annealing con warmup (10% de Ã©pocas)
  - ReducciÃ³n en plateau (patience=5, factor=0.5)
- **Batch Size**: 32 (ajustar segÃºn GPU)
- **Ã‰pocas**: 100 (con early stopping, patience=15)
- **FunciÃ³n de pÃ©rdida**: 
  - **Categorical Cross-Entropy** (estÃ¡ndar)
  - **Focal Loss** (opcional, para enfocarse en ejemplos difÃ­ciles)
  - **Label Smoothing** (0.1) para reducir overconfidence

### **RegularizaciÃ³n**:
- **Weight Decay**: 1e-4
- **Dropout**: 0.5 (primer Dense), 0.3 (segundo Dense)
- **Batch Normalization**: DespuÃ©s de cada Dense
- **Data Augmentation**: Agresivo (ver secciÃ³n siguiente)

---

## ğŸ¨ Data Augmentation (EstratÃ©gico)

### **Augmentations Base** (siempre activos):
- **Resize**: 256Ã—256 â†’ 224Ã—224 (crop central o aleatorio)
- **NormalizaciÃ³n**: Media=[0.485, 0.456, 0.406], Std=[0.229, 0.224, 0.225] (ImageNet)

### **Augmentations Aleatorios** (probabilidad 0.5-0.8):
- **RotaciÃ³n**: Â±30Â° (aves pueden estar en cualquier Ã¡ngulo)
- **Flip horizontal**: 0.5
- **Zoom**: 0.8-1.2
- **Brightness/Contrast**: Â±20%
- **Saturation**: Â±20%
- **Hue**: Â±10% (cuidado con colores distintivos)
- **Translation**: Â±10% (shift horizontal/vertical)
- **Cutout/Random Erasing**: 0.2 probabilidad, 8Ã—8 patches

### **Augmentations Especiales** (para clases minoritarias):
- **Mixup**: Î±=0.2 (mezcla suave de imÃ¡genes)
- **CutMix**: Î±=1.0 (mezcla de regiones)
- **AutoAugment**: PolÃ­ticas aprendidas (opcional)

---

## ğŸ“ˆ Estrategias para la Clase "no_oficiales"

### **DesafÃ­o**: 
La clase agrupa mÃºltiples especies diferentes, puede ser difÃ­cil de generalizar.

### **Soluciones**:

1. **Diversidad en entrenamiento**:
   - Asegurar que "no_oficiales" tenga variedad mÃ¡xima de especies
   - Si es posible, balancear sub-especies dentro de esta clase

2. **Threshold de confianza adaptativo**:
   - Si `max(softmax_output) < 0.6` â†’ clasificar como "no_oficiales"
   - Ajustar threshold en validaciÃ³n para optimizar F1

3. **Focal Loss ajustado**:
   - Dar mÃ¡s peso a "no_oficiales" en la funciÃ³n de pÃ©rdida
   - `Î±=0.25` para clases oficiales, `Î±=0.4` para "no_oficiales"

4. **Class Weights**:
   - Peso inversamente proporcional a frecuencia
   - Ajustar manualmente para "no_oficiales" si es necesario

---

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n (Comprehensivas)

### **MÃ©tricas Globales**:
- **Accuracy**: PrecisiÃ³n general
- **Top-1 Accuracy**: Clase predicha mÃ¡s probable
- **Top-3 Accuracy**: Â¿EstÃ¡ la clase correcta en top-3?
- **Macro F1-Score**: Promedio de F1 por clase (sin ponderar)
- **Weighted F1-Score**: Promedio ponderado por frecuencia

### **MÃ©tricas por Clase**:
- **Precision**: TP / (TP + FP)
- **Recall**: TP / (TP + FN)
- **F1-Score**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
- **Support**: NÃºmero de ejemplos reales

### **AnÃ¡lisis Avanzado**:
- **Matriz de confusiÃ³n 13Ã—13**: VisualizaciÃ³n completa
- **Classification Report**: Por clase y agregado
- **ROC Curves**: Por clase (one-vs-rest)
- **Precision-Recall Curves**: Por clase
- **Confidence Calibration**: Â¿Las probabilidades son calibradas?

---

## ğŸ”¬ ExperimentaciÃ³n SistemÃ¡tica

### **Experimentos Propuestos**:

1. **Baseline**: EfficientNet-B2, augmentations bÃ¡sicos
2. **Transfer Learning**: Comparar EfficientNet, ResNet50, ViT
3. **Ensemble**: Combinar mejores modelos individuales
4. **Data Augmentation**: AblaciÃ³n de augmentations
5. **Loss Functions**: Cross-Entropy vs Focal Loss vs Label Smoothing
6. **Class Weights**: Con y sin balanceo de clases
7. **Learning Rate Schedules**: Cosine vs Step vs Plateau
8. **Model Size**: EfficientNet-B0 vs B2 vs B3 (trade-off precisiÃ³n/velocidad)

### **ValidaciÃ³n**:
- **K-Fold Cross-Validation** (K=5): Para estimaciÃ³n robusta de mÃ©tricas
- **Stratified Split**: Mantener proporciÃ³n de clases en train/val/test

---

## ğŸ¨ Visualizaciones y AnÃ¡lisis

### **Visualizaciones Requeridas**:

1. **DistribuciÃ³n del Dataset**:
   - GrÃ¡fico de barras por clase
   - Ejemplos representativos por clase

2. **Curvas de Entrenamiento**:
   - Loss (train vs val) por Ã©poca
   - Accuracy (train vs val) por Ã©poca
   - Learning rate schedule

3. **Matriz de ConfusiÃ³n**:
   - Heatmap 13Ã—13 con valores normalizados
   - Anotaciones de valores absolutos

4. **AnÃ¡lisis de Errores**:
   - Ejemplos de falsos positivos/negativos
   - Clases mÃ¡s confundidas (pairwise confusion)

5. **Visualizaciones de Modelo** (opcional pero valorado):
   - **Grad-CAM**: Mapas de activaciÃ³n (Â¿quÃ© ve el modelo?)
   - **Feature Visualization**: VisualizaciÃ³n de filtros aprendidos
   - **t-SNE**: ProyecciÃ³n 2D de embeddings de Ãºltima capa

---

## ğŸš€ Pipeline de ML Completo

### **Estructura del Proyecto**:
```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dataset original
â”‚   â”œâ”€â”€ processed/        # ImÃ¡genes preprocesadas
â”‚   â””â”€â”€ splits/           # Train/val/test splits
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_baseline_training.ipynb
â”‚   â”œâ”€â”€ 04_model_comparison.ipynb
â”‚   â”œâ”€â”€ 05_ensemble.ipynb
â”‚   â””â”€â”€ 06_evaluation_analysis.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py     # Dataset class
â”‚   â”‚   â””â”€â”€ augmentation.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ efficientnet.py
â”‚   â”‚   â”œâ”€â”€ resnet.py
â”‚   â”‚   â””â”€â”€ ensemble.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ callbacks.py
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ visualization.py
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml        # HiperparÃ¡metros centralizados
â”œâ”€â”€ models/                # Modelos entrenados guardados
â”œâ”€â”€ results/               # MÃ©tricas, grÃ¡ficos, reportes
â””â”€â”€ app.py                 # Streamlit app para demo
```

---

## âœ… Checklist de Entregables

### **CÃ³digo**:
- [ ] Pipeline completo de preprocesamiento
- [ ] Scripts de entrenamiento reproducibles
- [ ] EvaluaciÃ³n comprehensiva
- [ ] Visualizaciones automatizadas
- [ ] App Streamlit funcional

### **DocumentaciÃ³n**:
- [ ] README con instrucciones claras
- [ ] Reporte de experimentos (quÃ© probaste, resultados)
- [ ] AnÃ¡lisis de errores detallado
- [ ] Conclusiones y mejoras futuras

### **Resultados**:
- [ ] Modelo(s) entrenado(s) guardados
- [ ] MÃ©tricas en formato tabular (CSV)
- [ ] GrÃ¡ficos de entrenamiento
- [ ] Matriz de confusiÃ³n
- [ ] Ejemplos de predicciones (correctas e incorrectas)

---

## ğŸ“ Valor Agregado para Proyecto Final

1. **Ensemble de modelos**: Demuestra comprensiÃ³n avanzada
2. **ExperimentaciÃ³n sistemÃ¡tica**: AblaciÃ³n studies, comparaciÃ³n de arquitecturas
3. **AnÃ¡lisis profundo**: Grad-CAM, anÃ¡lisis de errores, visualizaciones
4. **Pipeline profesional**: CÃ³digo modular, configurable, reproducible
5. **DocumentaciÃ³n completa**: README, reporte, visualizaciones

---

## ğŸ“ Notas Finales

- **Prioridad**: Robustez > Velocidad (es proyecto final, no producciÃ³n)
- **Reproducibilidad**: Semillas fijas, versionado de cÃ³digo
- **Ã‰tica**: CrÃ©ditos de dataset, licencias respetadas
- **Escalabilidad**: CÃ³digo preparado para agregar mÃ¡s especies fÃ¡cilmente

