# Entrenamiento del Modelo Clasificador: Clasificaci√≥n Multiclase de Especies Piciformes

## 1. Introducci√≥n

El presente documento describe el proceso de entrenamiento del modelo de clasificaci√≥n multiclase dise√±ado para identificar especies espec√≠ficas de aves pertenecientes al orden Piciformes.

Este modelo constituye la segunda etapa del sistema de clasificaci√≥n en cascada implementado en la aplicaci√≥n BirdID-Piciformes. Su funci√≥n es determinar la especie exacta de un ave Piciforme previamente identificada por el modelo binario de la primera etapa.

---

## 1.1 Diagramas del Pipeline de Entrenamiento

> **Nota:** Para exportar como imagen, copiar el c√≥digo Mermaid a [mermaid.live](https://mermaid.live) y descargar como PNG/SVG.

### Diagrama General del Pipeline

```mermaid
flowchart TB
    subgraph DATA["üìä 1. ORIGEN DE DATOS"]
        direction TB
        BC["üá®üá¥ BirdColombia<br/><i>Lista oficial Piciformes</i>"]
        IN["üåç iNaturalist<br/><i>Dataset biodiversidad</i>"]
        BC --> CROSS["‚à© Cruce de fuentes"]
        IN --> CROSS
        CROSS --> DATASET["üìÅ 13 Clases<br/>12 especies oficiales +<br/>1 'No Inventariado'"]
    end

    subgraph SPLIT["üìÇ 2. PARTICI√ìN"]
        direction LR
        DATASET --> TRAIN["üéì Train 70%<br/><i>Optimizaci√≥n</i>"]
        DATASET --> VAL["üìù Val 15%<br/><i>Monitoreo</i>"]
        DATASET --> TEST["üèÜ Test 15%<br/><i>Evaluaci√≥n</i>"]
    end

    subgraph AUG["üîÑ 3. DATA AUGMENTATION"]
        direction TB
        TRAIN --> AUGS
        subgraph AUGS["Transformaciones (Solo Train)"]
            A1["Rotation ¬±30¬∞"]
            A2["Flip H/V"]
            A3["Color Jitter"]
            A4["Random Crop"]
            A5["Gaussian Blur"]
            A6["Random Erasing"]
        end
    end

    subgraph PREPROCESS["‚öôÔ∏è 4. PREPROCESAMIENTO"]
        AUGS --> RESIZE["Resize: 256√ó256√ó3"]
        RESIZE --> NORM["Normalizaci√≥n ImageNet<br/>mean=[0.485, 0.456, 0.406]<br/>std=[0.229, 0.224, 0.225]"]
    end

    subgraph MODEL["üß† 5. ARQUITECTURA"]
        direction TB
        NORM --> BACKBONE["EfficientNet-B2<br/><i>PyTorch - ImageNet</i>"]
        BACKBONE --> HEAD["Clasificador Head<br/>512 ‚Üí 256 ‚Üí 13"]
    end

    subgraph TRAINING["üèãÔ∏è 6. ENTRENAMIENTO"]
        direction TB
        HEAD --> STAGE1["ETAPA 1<br/>Head Only<br/>üîí Backbone Congelado"]
        STAGE1 --> STAGE2["ETAPA 2<br/>Fine-Tuning<br/>üîì Todo Descongelado"]
    end

    subgraph OPTIM["‚ö° 7. OPTIMIZACI√ìN"]
        direction LR
        STAGE2 --> OPT["AdamW + Cosine Annealing"]
        OPT --> REG["Regularizaci√≥n:<br/>Dropout, Label Smoothing<br/>Class Weights, Grad Clip"]
    end

    subgraph EVAL["üìà 8. EVALUACI√ìN"]
        direction TB
        REG --> METRICS["M√©tricas:<br/>Accuracy, F1, Precision, Recall"]
        TEST --> METRICS
        METRICS --> CM["Matriz Confusi√≥n 13√ó13"]
        METRICS --> CURVES["Curvas de Entrenamiento"]
    end

    subgraph SAVE["üíæ 9. PERSISTENCIA"]
        direction LR
        CM --> PT[".pt (PyTorch)<br/><i>Checkpoint completo</i>"]
        PT --> HF["ü§ó Hugging Face Hub"]
    end

    style DATA fill:#e3f2fd
    style SPLIT fill:#fff3e0
    style AUG fill:#f3e5f5
    style PREPROCESS fill:#e8f5e9
    style MODEL fill:#fce4ec
    style TRAINING fill:#fff8e1
    style OPTIM fill:#e0f7fa
    style EVAL fill:#e0f2f1
    style SAVE fill:#f1f8e9
```

### Arquitectura Detallada de la Red (PyTorch)

```mermaid
flowchart TB
    subgraph INPUT["üì• Entrada"]
        IMG["Imagen RGB<br/>256 √ó 256 √ó 3"]
    end

    subgraph BACKBONE["üî∑ EfficientNet-B2 (PyTorch)"]
        direction TB
        CONV["backbone.features<br/>Bloques MBConv<br/>~9.2M par√°metros"]
        
        subgraph FREEZE["Estado durante entrenamiento"]
            F1["üîí Etapa 1: Congelado<br/><i>requires_grad=False</i>"]
            F2["üîì Etapa 2: Entrenable<br/><i>requires_grad=True</i>"]
        end
    end

    subgraph CLASSIFIER["üî∂ Clasificador Personalizado"]
        direction TB
        
        subgraph POOL["Reducci√≥n Espacial"]
            AAP["AdaptiveAvgPool2d(1)<br/>‚Üí (batch, channels, 1, 1)"]
            FLAT["Flatten()<br/>‚Üí (batch, 1408)"]
        end

        subgraph FC1["Capa Densa 1"]
            L1["Linear(1408 ‚Üí 512)"]
            BN1["BatchNorm1d(512)"]
            R1["ReLU()"]
            D1["Dropout(0.4)"]
        end

        subgraph FC2["Capa Densa 2"]
            L2["Linear(512 ‚Üí 256)"]
            BN2["BatchNorm1d(256)"]
            R2["ReLU()"]
            D2["Dropout(0.2)"]
        end

        subgraph OUT["Capa de Salida"]
            L3["Linear(256 ‚Üí 13)"]
            SM["Softmax<br/><i>(impl√≠cito en CrossEntropy)</i>"]
        end
    end

    subgraph OUTPUT["üì§ Salida"]
        direction LR
        C0["Clase 0<br/>A. prasinus"]
        C1["Clase 1<br/>C. melanoleucos"]
        CD["..."]
        C12["Clase 12<br/>R. sulfuratus"]
    end

    IMG --> CONV
    CONV --> AAP
    AAP --> FLAT
    FLAT --> L1 --> BN1 --> R1 --> D1
    D1 --> L2 --> BN2 --> R2 --> D2
    D2 --> L3 --> SM
    SM --> C0
    SM --> C1
    SM --> CD
    SM --> C12

    style INPUT fill:#bbdefb
    style BACKBONE fill:#c8e6c9
    style CLASSIFIER fill:#ffccbc
    style OUTPUT fill:#d1c4e9
```

### Proceso de Entrenamiento en Dos Etapas

```mermaid
flowchart TB
    subgraph INIT["üöÄ Inicializaci√≥n"]
        direction TB
        LOAD["Cargar EfficientNet-B2<br/>weights='ImageNet'"]
        WEIGHTS["Calcular Class Weights<br/><i>Balanceo de clases</i>"]
        LOAD --> MODEL["Modelo inicializado"]
        WEIGHTS --> LOSS["CrossEntropyLoss<br/>+ label_smoothing=0.05"]
    end

    subgraph STAGE1["üîí ETAPA 1: Entrenamiento del Head"]
        direction TB
        
        S1_FREEZE["freeze_backbone(model)<br/><i>Solo Head entrenable</i>"]
        
        subgraph S1_CONFIG["Configuraci√≥n"]
            S1_EP["√âpocas: 20"]
            S1_LR["LR: 6√ó10‚Åª‚Å¥"]
            S1_OPT["AdamW"]
            S1_SCH["Cosine Annealing"]
            S1_PAT["Early Stop: 10 √©pocas"]
        end

        subgraph S1_LOOP["Bucle de Entrenamiento"]
            S1_FWD["Forward Pass"]
            S1_LOSS["Loss + Class Weights"]
            S1_BWD["Backward Pass"]
            S1_CLIP["Gradient Clipping (1.0)"]
            S1_STEP["Optimizer Step"]
        end

        S1_FREEZE --> S1_CONFIG
        S1_CONFIG --> S1_LOOP
        S1_LOOP --> S1_VAL["Validaci√≥n por √©poca"]
        S1_VAL --> S1_SAVE["Guardar mejor modelo"]
    end

    subgraph STAGE2["üîì ETAPA 2: Fine-Tuning Completo"]
        direction TB
        
        S2_UNFREEZE["unfreeze_backbone(model)<br/><i>Todo entrenable</i>"]
        
        subgraph S2_CONFIG["Configuraci√≥n"]
            S2_EP["√âpocas: 80"]
            S2_LR["LR: 3√ó10‚Åª‚Å¥"]
            S2_OPT["AdamW"]
            S2_SCH["Cosine Annealing<br/>Œ∑_min=1√ó10‚Åª‚Å∑"]
            S2_PAT["Early Stop: 20 √©pocas"]
        end

        subgraph S2_LOOP["Bucle de Entrenamiento"]
            S2_FWD["Forward Pass"]
            S2_LOSS["Loss + Class Weights"]
            S2_BWD["Backward Pass"]
            S2_CLIP["Gradient Clipping (1.0)"]
            S2_STEP["Optimizer Step"]
        end

        S2_UNFREEZE --> S2_CONFIG
        S2_CONFIG --> S2_LOOP
        S2_LOOP --> S2_VAL["Validaci√≥n por √©poca"]
        S2_VAL --> S2_SAVE["Guardar mejor modelo"]
    end

    subgraph EVAL["üìä Evaluaci√≥n Final"]
        direction TB
        LOAD_BEST["Cargar mejor checkpoint"]
        TEST_EVAL["Evaluar en Test Set"]
        REPORT["Classification Report<br/>13 clases"]
        CONFMAT["Matriz de Confusi√≥n"]
        CURVES["Curvas Loss/Accuracy"]
        
        LOAD_BEST --> TEST_EVAL
        TEST_EVAL --> REPORT
        TEST_EVAL --> CONFMAT
        TEST_EVAL --> CURVES
    end

    INIT --> STAGE1
    STAGE1 --> STAGE2
    STAGE2 --> EVAL

    style INIT fill:#e8eaf6
    style STAGE1 fill:#e3f2fd
    style STAGE2 fill:#fff3e0
    style EVAL fill:#e8f5e9
```

### Data Augmentation Pipeline

```mermaid
flowchart LR
    subgraph INPUT["Imagen Original"]
        IMG["üñºÔ∏è Variable size"]
    end

    subgraph TRANSFORMS["Transformaciones Secuenciales"]
        direction TB
        T1["Resize(288, 288)"]
        T2["RandomCrop(256)"]
        T3["RandomRotation(30¬∞)"]
        T4["RandomHorizontalFlip(0.5)"]
        T5["RandomVerticalFlip(0.1)"]
        T6["RandomResizedCrop<br/>scale=(0.85, 1.0)"]
        T7["ColorJitter<br/>brightness=0.2<br/>contrast=0.2<br/>saturation=0.2<br/>hue=0.1"]
        T8["RandomAffine<br/>translate=(0.1, 0.1)"]
        T9["GaussianBlur(3)<br/>p=0.2"]
        T10["ToTensor()"]
        T11["Normalize(ImageNet)"]
        T12["RandomErasing<br/>p=0.2"]
    end

    subgraph OUTPUT["Tensor de Salida"]
        OUT["üì¶ (3, 256, 256)<br/>Normalizado"]
    end

    IMG --> T1 --> T2 --> T3 --> T4 --> T5 --> T6 --> T7 --> T8 --> T9 --> T10 --> T11 --> T12 --> OUT

    style INPUT fill:#ffecb3
    style TRANSFORMS fill:#e1f5fe
    style OUTPUT fill:#c8e6c9
```

### Flujo de Inferencia (Producci√≥n)

```mermaid
flowchart LR
    subgraph STEP1["Paso 1: Identificador"]
        ID_IN["üñºÔ∏è Imagen"]
        ID_MODEL["Modelo Binario<br/><i>TensorFlow</i>"]
        ID_OUT{"¬øPiciforme?"}
        
        ID_IN --> ID_MODEL --> ID_OUT
    end

    subgraph STEP2["Paso 2: Clasificador"]
        CL_PRE["Preprocesamiento<br/>224√ó224, ImageNet Norm"]
        CL_MODEL["EfficientNet-B2<br/><i>PyTorch</i>"]
        CL_SOFT["Softmax"]
        CL_OUT["Top-5 Predicciones"]
        
        CL_PRE --> CL_MODEL --> CL_SOFT --> CL_OUT
    end

    subgraph RESULT["Resultado Final"]
        SPECIES["üê¶ Especie identificada<br/>+ Confianza"]
    end

    ID_OUT -->|"‚úÖ S√≠"| CL_PRE
    ID_OUT -->|"‚ùå No"| STOP["‚õî No clasificar"]
    CL_OUT --> SPECIES

    style STEP1 fill:#e3f2fd
    style STEP2 fill:#fff3e0
    style RESULT fill:#e8f5e9
```

---

## 2. Conjunto de Datos

### 2.1 Origen y Selecci√≥n de Especies

Las especies incluidas en el modelo fueron seleccionadas mediante el **cruce de dos fuentes de datos**:

1. **BirdColombia:** Lista oficial de especies del orden Piciformes reportadas para Colombia.
2. **iNaturalist:** Dataset de observaciones de biodiversidad con im√°genes etiquetadas por especie.

Este cruce garantiza que las especies seleccionadas cumplan dos criterios: (1) relevancia taxon√≥mica para la avifauna colombiana, y (2) disponibilidad suficiente de im√°genes para entrenamiento supervisado.

### 2.2 Descripci√≥n del Dataset

El conjunto de datos comprende im√°genes de **13 clases** de aves Piciformes:

| Clase | Especie | Familia | Origen |
|-------|---------|---------|--------|
| 0 | Aulacorhynchus prasinus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 1 | Campephilus melanoleucos | Picidae | BirdColombia ‚à© iNaturalist |
| 2 | Colaptes punctigula | Picidae | BirdColombia ‚à© iNaturalist |
| 3 | Colaptes rubiginosus | Picidae | BirdColombia ‚à© iNaturalist |
| 4 | Dryocopus lineatus | Picidae | BirdColombia ‚à© iNaturalist |
| 5 | Melanerpes formicivorus | Picidae | BirdColombia ‚à© iNaturalist |
| 6 | Melanerpes pucherani | Picidae | BirdColombia ‚à© iNaturalist |
| 7 | Melanerpes rubricapillus | Picidae | BirdColombia ‚à© iNaturalist |
| 8 | Piciforme No Inventariado | ‚Äî | iNaturalist \ BirdColombia |
| 9 | Pteroglossus castanotis | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 10 | Pteroglossus torquatus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 11 | Ramphastos ambiguus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 12 | Ramphastos sulfuratus | Ramphastidae | BirdColombia ‚à© iNaturalist |

**Nota:** La clase "Piciforme No Inventariado" agrupa especies de Piciformes presentes en iNaturalist que no est√°n registradas en la lista oficial de BirdColombia, permitiendo al modelo manejar especies fuera del inventario nacional.

### 2.3 Partici√≥n del Dataset

Se aplic√≥ una estrategia de partici√≥n aleatoria estratificada con semilla fija (seed=42) para garantizar reproducibilidad:

| Partici√≥n | Proporci√≥n | Prop√≥sito |
|-----------|------------|-----------|
| Entrenamiento | 70% | Optimizaci√≥n de par√°metros del modelo |
| Validaci√≥n | 15% | Monitoreo del sobreajuste durante entrenamiento |
| Prueba | 15% | Evaluaci√≥n final del rendimiento |

---

## 3. Arquitectura del Modelo

### 3.1 Enfoque de Transfer Learning

Se emple√≥ la t√©cnica de Transfer Learning utilizando como backbone el modelo **EfficientNet-B2** (alternativa: EfficientNet-B3) pre-entrenado en el dataset ImageNet. Esta estrategia permite aprovechar las representaciones de caracter√≠sticas aprendidas en un corpus de 1.2 millones de im√°genes con 1000 categor√≠as.

### 3.2 Framework de Implementaci√≥n

A diferencia del modelo identificador (implementado en TensorFlow/Keras), el modelo clasificador fue desarrollado en **PyTorch**, permitiendo mayor flexibilidad en la definici√≥n de estrategias de entrenamiento personalizadas.

### 3.3 Estructura de la Red

**Entrada:**
- Dimensiones: 256 √ó 256 √ó 3 (RGB)
- Preprocesamiento: Normalizaci√≥n ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

**Backbone (EfficientNet-B2):**
- Capas convolucionales pre-entrenadas en ImageNet
- Extracci√≥n de caracter√≠sticas de alto nivel
- Clasificador original reemplazado por Identity

**Clasificador Personalizado (Head):**

| Capa | Configuraci√≥n | Funci√≥n de activaci√≥n |
|------|---------------|----------------------|
| Adaptive Average Pooling 2D | Reducci√≥n a 1√ó1 | - |
| Flatten | Vectorizaci√≥n | - |
| Linear | 512 unidades | - |
| BatchNorm1d | Normalizaci√≥n | - |
| ReLU | Activaci√≥n | ReLU |
| Dropout | rate = 0.4 | - |
| Linear | 256 unidades | - |
| BatchNorm1d | Normalizaci√≥n | - |
| ReLU | Activaci√≥n | ReLU |
| Dropout | rate = 0.2 | - |
| Linear (salida) | 13 unidades | Softmax (impl√≠cito en CrossEntropy) |

### 3.4 T√©cnicas de Regularizaci√≥n

Se implementaron m√∫ltiples estrategias de regularizaci√≥n para prevenir sobreajuste:

| T√©cnica | Configuraci√≥n | Prop√≥sito |
|---------|---------------|-----------|
| Dropout | 40% / 20% | Desactivaci√≥n aleatoria de neuronas |
| BatchNormalization | Por capa densa | Estabilizaci√≥n del entrenamiento |
| Label Smoothing | 0.05 | Suavizado de etiquetas para mejor generalizaci√≥n |
| Weight Decay | 1√ó10‚Åª‚Å¥ | Regularizaci√≥n L2 en pesos |
| Gradient Clipping | max_norm=1.0 | Prevenci√≥n de gradientes explosivos |
| Class Weights | Inversamente proporcional | Balanceo de clases desbalanceadas |

---

## 4. Proceso de Entrenamiento

### 4.1 Estrategia de Dos Etapas

El entrenamiento se realiz√≥ en dos etapas secuenciales, siguiendo las mejores pr√°cticas de fine-tuning para Transfer Learning:

#### Etapa 1: Entrenamiento del Head (Backbone Congelado)

| Par√°metro | Valor |
|-----------|-------|
| √âpocas | 20 (o 25% del total) |
| Learning rate | 6 √ó 10‚Åª‚Å¥ (2√ó LR base) |
| Optimizador | AdamW |
| Scheduler | Cosine Annealing |
| Early stopping patience | 10 √©pocas |
| Backbone | Congelado (requires_grad=False) |

**Objetivo:** Entrenar exclusivamente las capas del clasificador personalizado mientras el backbone EfficientNet permanece fijo, evitando la destrucci√≥n de representaciones pre-entrenadas durante la adaptaci√≥n inicial.

#### Etapa 2: Fine-Tuning Completo

| Par√°metro | Valor |
|-----------|-------|
| √âpocas | 80 (restantes) |
| Learning rate | 3 √ó 10‚Åª‚Å¥ |
| Optimizador | AdamW |
| Scheduler | Cosine Annealing (Œ∑_min = 1√ó10‚Åª‚Å∑) |
| Early stopping patience | 20 √©pocas |
| Backbone | Descongelado (requires_grad=True) |

**Objetivo:** Ajuste fino de todo el modelo, incluyendo las capas del backbone, para especializar las representaciones de caracter√≠sticas en el dominio espec√≠fico de especies Piciformes.

### 4.2 Data Augmentation

Durante el entrenamiento se aplicaron transformaciones extensivas para aumentar la variabilidad del conjunto de datos:

| Transformaci√≥n | Par√°metros | Justificaci√≥n |
|----------------|------------|---------------|
| Resize + Random Crop | 288‚Üí256 px | Variabilidad en encuadre |
| Random Rotation | ¬±30¬∞ | Orientaci√≥n variable de aves |
| Horizontal Flip | p=0.5 | Simetr√≠a bilateral |
| Vertical Flip | p=0.1 | Aves en posiciones invertidas |
| Random Resized Crop | scale=(0.85, 1.0) | Zoom variable |
| Color Jitter | brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1 | Variabilidad lum√≠nica |
| Random Affine | translate=(0.1, 0.1), scale=(0.9, 1.1) | Desplazamiento y escala |
| Gaussian Blur | kernel=3, p=0.2 | Robustez a desenfoque |
| Random Erasing | p=0.2, scale=(0.02, 0.15) | Oclusi√≥n parcial |

### 4.3 Funci√≥n de P√©rdida

Se utiliz√≥ **Cross-Entropy Loss** con las siguientes modificaciones:

```
L = CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)
```

- **Class Weights:** Calculados como inversamente proporcionales a la frecuencia de cada clase, mitigando el desbalance del dataset.
- **Label Smoothing:** Factor de 0.05 para prevenir sobreconfianza en predicciones.

### 4.4 Optimizador y Scheduler

**Optimizador:** AdamW (Adam con Weight Decay desacoplado)
- Learning rate inicial: 3 √ó 10‚Åª‚Å¥
- Weight decay: 1 √ó 10‚Åª‚Å¥
- Betas: (0.9, 0.999)

**Learning Rate Scheduler:** Cosine Annealing
- T_max: n√∫mero de √©pocas de la etapa
- Œ∑_min: 1 √ó 10‚Åª‚Å∑

La estrategia de Cosine Annealing permite una reducci√≥n suave del learning rate, facilitando la convergencia a m√≠nimos m√°s estables.

---

## 5. Implementaci√≥n

### 5.1 Gesti√≥n de Datos

El script implementa una clase `SubsetDataset` que permite aplicar transformaciones diferenciadas a cada partici√≥n del dataset:

```python
class SubsetDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform):
        self.dataset = dataset
        self.indices = list(indices)
        self.transform = transform
```

Esta implementaci√≥n garantiza que las transformaciones de augmentation solo se apliquen al conjunto de entrenamiento, mientras validaci√≥n y prueba utilizan √∫nicamente normalizaci√≥n.

### 5.2 Bucle de Entrenamiento

Cada √©poca ejecuta:

1. **Forward pass:** Propagaci√≥n de im√°genes a trav√©s de la red
2. **C√°lculo de p√©rdida:** Cross-Entropy con pesos de clase
3. **Backward pass:** C√°lculo de gradientes mediante autograd
4. **Gradient clipping:** Limitaci√≥n de norma m√°xima a 1.0
5. **Actualizaci√≥n de pesos:** Paso del optimizador
6. **Actualizaci√≥n del scheduler:** Ajuste del learning rate

### 5.3 Criterio de Early Stopping

El entrenamiento se detiene anticipadamente si no se observa mejora en la accuracy de validaci√≥n durante un n√∫mero consecutivo de √©pocas (patience):

- Etapa 1: patience = 10 √©pocas
- Etapa 2: patience = 20 √©pocas

El mejor modelo (seg√∫n accuracy de validaci√≥n) se guarda autom√°ticamente durante el entrenamiento.

---

## 6. Resultados

### 6.1 M√©tricas de Evaluaci√≥n

La evaluaci√≥n se realiza sobre el conjunto de prueba utilizando las siguientes m√©tricas:

| M√©trica | Descripci√≥n |
|---------|-------------|
| Accuracy | Proporci√≥n de clasificaciones correctas |
| Precision | TP / (TP + FP) por clase |
| Recall | TP / (TP + FN) por clase |
| F1-Score | Media arm√≥nica de Precision y Recall |
| Macro Average | Promedio no ponderado entre clases |
| Weighted Average | Promedio ponderado por soporte |

### 6.2 Visualizaciones Generadas

El script genera autom√°ticamente:

1. **Matriz de Confusi√≥n** (`confusion_matrix.png`): Visualizaci√≥n de predicciones vs etiquetas reales para las 13 clases.

2. **Curvas de Entrenamiento** (`training_curves.png`): Evoluci√≥n de loss y accuracy durante las √©pocas de entrenamiento.

---

## 7. Persistencia del Modelo

### 7.1 Formato PyTorch

El modelo se guarda en formato `.pt` incluyendo:

```python
{
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'val_acc': val_acc,
    'config': config
}
```

Esta estructura permite:
- Reanudar entrenamiento desde checkpoint
- Reconstruir la arquitectura exacta usando la configuraci√≥n guardada
- Acceder a m√©tricas del momento del guardado

### 7.2 Exportaci√≥n a Keras (Opcional)

El script incluye funcionalidad para exportar una arquitectura equivalente en formato Keras (`.keras`), facilitando la interoperabilidad entre frameworks.

---

## 8. Infraestructura Computacional

El entrenamiento est√° optimizado para ejecutarse en **Google Colaboratory** con los siguientes recursos:

| Componente | Especificaci√≥n |
|------------|----------------|
| GPU | NVIDIA T4 / V100 / A100 |
| Framework | PyTorch 2.x |
| CUDA | Compatible con GPU disponible |
| Workers | 2 (para DataLoader) |
| Pin Memory | Habilitado para GPU |

### 8.1 Optimizaciones de Rendimiento

- **Gradient Clipping:** Prevenci√≥n de inestabilidad num√©rica
- **Pin Memory:** Transferencia as√≠ncrona CPU‚ÜíGPU
- **Num Workers:** Carga paralela de datos
- **Mixed Precision:** Compatible (no habilitado por defecto)

---

## 9. Configuraci√≥n

### 9.1 Par√°metros por Defecto

```yaml
data:
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  image_size: 256
  num_classes: 13
  seed: 42

model:
  architecture: efficientnet_b2
  pretrained: true
  dropout_rate_1: 0.4
  dropout_rate_2: 0.2
  hidden_dim_1: 512
  hidden_dim_2: 256

training:
  batch_size: 32
  epochs: 100
  early_stopping_patience: 20
  learning_rate: 0.0003
  weight_decay: 0.0001
  optimizer: adamw
  label_smoothing: 0.05
  use_class_weights: true
  lr_schedule:
    type: cosine
    min_lr: 1e-7
```

### 9.2 Arquitecturas Soportadas

| Arquitectura | Par√°metros | Tama√±o entrada recomendado |
|--------------|------------|---------------------------|
| efficientnet_b0 | 5.3M | 224√ó224 |
| efficientnet_b2 | 9.2M | 260√ó260 |
| efficientnet_b3 | 12.0M | 300√ó300 |
| resnet50 | 25.6M | 224√ó224 |

---

## 10. Integraci√≥n con el Sistema

Este modelo se integra como segunda etapa del pipeline de clasificaci√≥n:

1. El modelo identificador determina que la imagen contiene un Piciforme
2. La imagen se redimensiona a 224√ó224 p√≠xeles (o 256√ó256 seg√∫n configuraci√≥n)
3. Se aplica normalizaci√≥n ImageNet
4. El clasificador genera probabilidades para las 13 especies
5. Se selecciona la clase con mayor probabilidad como predicci√≥n final

---

## 11. Conclusiones

El modelo de clasificaci√≥n multiclase implementa una arquitectura robusta basada en EfficientNet con m√∫ltiples t√©cnicas de regularizaci√≥n y una estrategia de entrenamiento en dos etapas. La combinaci√≥n de Transfer Learning, Data Augmentation extensivo y balanceo de clases permite obtener un clasificador generalizable para el dominio espec√≠fico de especies Piciformes.

La modularidad del c√≥digo facilita la experimentaci√≥n con diferentes arquitecturas backbone y configuraciones de hiperpar√°metros.

---

## Referencias

- Tan, M., & Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. *International Conference on Machine Learning (ICML)*.
- Loshchilov, I., & Hutter, F. (2019). Decoupled Weight Decay Regularization. *International Conference on Learning Representations (ICLR)*.
- M√ºller, R., Kornblith, S., & Hinton, G. (2019). When Does Label Smoothing Help? *Advances in Neural Information Processing Systems (NeurIPS)*.
- PyTorch Documentation. (2024). https://pytorch.org/docs/

---

**Documento t√©cnico - Proyecto BirdID-Piciformes**  
*Maestr√≠a en Ingenier√≠a de la Informaci√≥n (MINE) - 2025*

