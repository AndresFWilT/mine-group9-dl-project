# Entrenamiento del Modelo Clasificador: Clasificaci√≥n Multiclase de Especies Piciformes

## 1. Introducci√≥n

El presente documento describe el proceso de entrenamiento del modelo de clasificaci√≥n multiclase dise√±ado para identificar especies espec√≠ficas de aves pertenecientes al orden Piciformes.

Este modelo constituye la segunda etapa del sistema de clasificaci√≥n en cascada implementado en la aplicaci√≥n BirdID-Piciformes. Su funci√≥n es determinar la especie exacta de un ave Piciforme previamente identificada por el modelo binario de la primera etapa.

---

## 1.1 Diagramas del Pipeline de Entrenamiento

> **Nota:** Para exportar como imagen, copiar el c√≥digo Mermaid a [mermaid.live](https://mermaid.live) y descargar como PNG/SVG.

### Diagrama General del Pipeline

```mermaid
flowchart TB
    subgraph DATA["1. Datos"]
        BC["üá®üá¥ BirdColombia<br/>Lista oficial"]
        IN["üåç iNaturalist<br/>Dataset im√°genes"]
        BC --> CROSS["‚à© Cruce"]
        IN --> CROSS
        CROSS --> DATASET["13 Clases"]
    end

    subgraph SPLIT["2. Partici√≥n"]
        TRAIN["Train 70%"]
        VAL["Val 15%"]
        TEST["Test 15%"]
    end

    subgraph AUG["3. Augmentation"]
        AUG_LIST["Rotation ¬±30¬∞<br/>Flip H/V<br/>ColorJitter<br/>RandomCrop<br/>GaussianBlur<br/>RandomErasing"]
    end

    subgraph PRE["4. Preprocesamiento"]
        RESIZE["Resize 256√ó256"]
        NORM["Normalize ImageNet"]
    end

    subgraph ARCH["5. Arquitectura"]
        BACKBONE["EfficientNet-B2<br/>PyTorch ImageNet"]
        HEAD["Head 512‚Üí256‚Üí13"]
    end

    subgraph TRAIN_PROC["6. Entrenamiento"]
        STAGE1["üîí Etapa 1<br/>Head Only"]
        STAGE2["üîì Etapa 2<br/>Fine-Tuning"]
    end

    subgraph OPTIM["7. Optimizaci√≥n"]
        OPT["AdamW<br/>Cosine Annealing"]
        REG["Dropout + L2<br/>Label Smoothing"]
    end

    subgraph EVAL["8. Evaluaci√≥n"]
        METRICS["Accuracy, F1<br/>Precision, Recall"]
        CM["Confusion Matrix"]
    end

    subgraph PERSIST["9. Persistencia"]
        PT[".pt checkpoint"]
        HF["ü§ó HuggingFace"]
    end

    DATASET --> TRAIN & VAL & TEST
    TRAIN --> AUG_LIST --> RESIZE --> NORM
    NORM --> BACKBONE --> HEAD
    HEAD --> STAGE1 --> STAGE2
    STAGE2 --> OPT --> REG
    REG --> METRICS
    TEST --> METRICS
    METRICS --> CM --> PT --> HF

    style DATA fill:#e3f2fd
    style SPLIT fill:#fff3e0
    style AUG fill:#f3e5f5
    style PRE fill:#e8f5e9
    style ARCH fill:#fce4ec
    style TRAIN_PROC fill:#fff8e1
    style OPTIM fill:#e0f7fa
    style EVAL fill:#e0f2f1
    style PERSIST fill:#f1f8e9
```

### Arquitectura Detallada de la Red (PyTorch)

```mermaid
flowchart TB
    subgraph INPUT["Entrada"]
        IMG["üñºÔ∏è RGB 256√ó256√ó3"]
    end

    subgraph BACKBONE["EfficientNet-B2"]
        CONV["Bloques MBConv<br/>~9.2M params"]
        FREEZE_INFO["üîí Etapa 1: Congelado<br/>üîì Etapa 2: Entrenable"]
    end

    subgraph HEAD["Clasificador Head"]
        subgraph POOL["Pooling"]
            AAP["AdaptiveAvgPool2d(1)"]
            FLAT["Flatten ‚Üí 1408"]
        end

        subgraph FC1["Capa Densa 1"]
            L1["Linear(1408, 512)"]
            BN1["BatchNorm1d + ReLU"]
            D1["Dropout(0.4)"]
        end

        subgraph FC2["Capa Densa 2"]
            L2["Linear(512, 256)"]
            BN2["BatchNorm1d + ReLU"]
            D2["Dropout(0.2)"]
        end

        subgraph OUT["Salida"]
            L3["Linear(256, 13)"]
            SM["Softmax"]
        end
    end

    subgraph OUTPUT["Predicci√≥n"]
        C0["A. prasinus"]
        C1["C. melanoleucos"]
        CD["..."]
        C12["R. sulfuratus"]
    end

    IMG --> CONV --> AAP --> FLAT
    FLAT --> L1 --> BN1 --> D1
    D1 --> L2 --> BN2 --> D2
    D2 --> L3 --> SM
    SM --> C0 & C1 & CD & C12

    style INPUT fill:#bbdefb
    style BACKBONE fill:#c8e6c9
    style HEAD fill:#ffccbc
    style OUTPUT fill:#d1c4e9
```

### Proceso de Entrenamiento en Dos Etapas

```mermaid
flowchart TB
    subgraph INIT["Inicializaci√≥n"]
        LOAD["Cargar EfficientNet-B2<br/>weights=ImageNet"]
        WEIGHTS["Calcular Class Weights"]
        LOSS["CrossEntropyLoss<br/>label_smoothing=0.05"]
    end

    subgraph STAGE1["üîí Etapa 1: Head Only"]
        S1_DESC["Backbone congelado<br/>Solo entrena clasificador"]
        S1_CONFIG["√âpocas: 20 | LR: 6√ó10‚Åª‚Å¥<br/>AdamW + Cosine<br/>Early Stop: 10"]
        S1_LOOP["Forward ‚Üí Loss ‚Üí Backward<br/>Gradient Clip ‚Üí Update"]
        S1_VAL["Validaci√≥n + Checkpoint"]
    end

    subgraph STAGE2["üîì Etapa 2: Fine-Tuning"]
        S2_DESC["Todo descongelado<br/>Entrena modelo completo"]
        S2_CONFIG["√âpocas: 80 | LR: 3√ó10‚Åª‚Å¥<br/>AdamW + Cosine<br/>Early Stop: 20"]
        S2_LOOP["Forward ‚Üí Loss ‚Üí Backward<br/>Gradient Clip ‚Üí Update"]
        S2_VAL["Validaci√≥n + Checkpoint"]
    end

    subgraph EVAL["Evaluaci√≥n Final"]
        LOAD_BEST["Cargar mejor checkpoint"]
        TEST_EVAL["Evaluar en Test Set"]
        RESULTS["Classification Report<br/>Confusion Matrix<br/>Training Curves"]
    end

    LOAD --> LOSS
    WEIGHTS --> LOSS
    INIT --> STAGE1
    S1_DESC --> S1_CONFIG --> S1_LOOP --> S1_VAL
    STAGE1 --> STAGE2
    S2_DESC --> S2_CONFIG --> S2_LOOP --> S2_VAL
    STAGE2 --> EVAL
    LOAD_BEST --> TEST_EVAL --> RESULTS

    style INIT fill:#e8eaf6
    style STAGE1 fill:#e3f2fd
    style STAGE2 fill:#fff3e0
    style EVAL fill:#e8f5e9
```

### Data Augmentation Pipeline

```mermaid
flowchart LR
    subgraph INPUT["Entrada"]
        IMG["üñºÔ∏è Imagen<br/>tama√±o variable"]
    end

    subgraph GEOM["Geom√©tricas"]
        T1["Resize(288)"]
        T2["RandomCrop(256)"]
        T3["Rotation(¬±30¬∞)"]
        T4["HFlip(p=0.5)"]
        T5["VFlip(p=0.1)"]
    end

    subgraph COLOR["Color"]
        T6["ResizedCrop"]
        T7["ColorJitter"]
        T8["Affine"]
        T9["GaussianBlur"]
    end

    subgraph TENSOR["Tensorizaci√≥n"]
        T10["ToTensor()"]
        T11["Normalize(ImageNet)"]
        T12["RandomErasing"]
    end

    subgraph OUTPUT["Salida"]
        OUT["üì¶ Tensor<br/>3√ó256√ó256"]
    end

    IMG --> T1 --> T2 --> T3 --> T4 --> T5
    T5 --> T6 --> T7 --> T8 --> T9
    T9 --> T10 --> T11 --> T12 --> OUT

    style INPUT fill:#ffecb3
    style GEOM fill:#e1f5fe
    style COLOR fill:#f3e5f5
    style TENSOR fill:#e8f5e9
    style OUTPUT fill:#c8e6c9
```

---

## 2. Conjunto de Datos

### 2.1 Origen y Selecci√≥n de Especies

Las especies incluidas en el modelo fueron seleccionadas mediante el **cruce de dos fuentes de datos**:

1. **BirdColombia:** Lista oficial de especies del orden Piciformes reportadas para Colombia.
2. **iNaturalist:** Dataset de observaciones de biodiversidad con im√°genes etiquetadas por especie.

Este cruce garantiza que las especies seleccionadas cumplan dos criterios: (1) relevancia taxon√≥mica para la avifauna colombiana, y (2) disponibilidad suficiente de im√°genes para entrenamiento supervisado.

### 2.2 Descripci√≥n del Dataset

El conjunto de datos comprende im√°genes de **13 clases** de aves Piciformes:

| Clase | Especie | Familia | Origen |
|-------|---------|---------|--------|
| 0 | Aulacorhynchus prasinus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 1 | Campephilus melanoleucos | Picidae | BirdColombia ‚à© iNaturalist |
| 2 | Colaptes punctigula | Picidae | BirdColombia ‚à© iNaturalist |
| 3 | Colaptes rubiginosus | Picidae | BirdColombia ‚à© iNaturalist |
| 4 | Dryocopus lineatus | Picidae | BirdColombia ‚à© iNaturalist |
| 5 | Melanerpes formicivorus | Picidae | BirdColombia ‚à© iNaturalist |
| 6 | Melanerpes pucherani | Picidae | BirdColombia ‚à© iNaturalist |
| 7 | Melanerpes rubricapillus | Picidae | BirdColombia ‚à© iNaturalist |
| 8 | Piciforme No Inventariado | ‚Äî | iNaturalist \ BirdColombia |
| 9 | Pteroglossus castanotis | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 10 | Pteroglossus torquatus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 11 | Ramphastos ambiguus | Ramphastidae | BirdColombia ‚à© iNaturalist |
| 12 | Ramphastos sulfuratus | Ramphastidae | BirdColombia ‚à© iNaturalist |

**Nota:** La clase "Piciforme No Inventariado" agrupa especies de Piciformes presentes en iNaturalist que no est√°n registradas en la lista oficial de BirdColombia, permitiendo al modelo manejar especies fuera del inventario nacional.

### 2.3 Partici√≥n del Dataset

Se aplic√≥ una estrategia de partici√≥n aleatoria estratificada con semilla fija (seed=42) para garantizar reproducibilidad:

| Partici√≥n | Proporci√≥n | Prop√≥sito |
|-----------|------------|-----------|
| Entrenamiento | 70% | Optimizaci√≥n de par√°metros del modelo |
| Validaci√≥n | 15% | Monitoreo del sobreajuste durante entrenamiento |
| Prueba | 15% | Evaluaci√≥n final del rendimiento |

---

## 3. Arquitectura del Modelo

### 3.1 Enfoque de Transfer Learning

Se emple√≥ la t√©cnica de Transfer Learning utilizando como backbone el modelo **EfficientNet-B2** (alternativa: EfficientNet-B3) pre-entrenado en el dataset ImageNet. Esta estrategia permite aprovechar las representaciones de caracter√≠sticas aprendidas en un corpus de 1.2 millones de im√°genes con 1000 categor√≠as.

### 3.2 Framework de Implementaci√≥n

A diferencia del modelo identificador (implementado en TensorFlow/Keras), el modelo clasificador fue desarrollado en **PyTorch**, permitiendo mayor flexibilidad en la definici√≥n de estrategias de entrenamiento personalizadas.

### 3.3 Estructura de la Red

**Entrada:**
- Dimensiones: 256 √ó 256 √ó 3 (RGB)
- Preprocesamiento: Normalizaci√≥n ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

**Backbone (EfficientNet-B2):**
- Capas convolucionales pre-entrenadas en ImageNet
- Extracci√≥n de caracter√≠sticas de alto nivel
- Clasificador original reemplazado por Identity

**Clasificador Personalizado (Head):**

| Capa | Configuraci√≥n | Funci√≥n de activaci√≥n |
|------|---------------|----------------------|
| Adaptive Average Pooling 2D | Reducci√≥n a 1√ó1 | - |
| Flatten | Vectorizaci√≥n | - |
| Linear | 512 unidades | - |
| BatchNorm1d | Normalizaci√≥n | - |
| ReLU | Activaci√≥n | ReLU |
| Dropout | rate = 0.4 | - |
| Linear | 256 unidades | - |
| BatchNorm1d | Normalizaci√≥n | - |
| ReLU | Activaci√≥n | ReLU |
| Dropout | rate = 0.2 | - |
| Linear (salida) | 13 unidades | Softmax (impl√≠cito en CrossEntropy) |

### 3.4 T√©cnicas de Regularizaci√≥n

Se implementaron m√∫ltiples estrategias de regularizaci√≥n para prevenir sobreajuste:

| T√©cnica | Configuraci√≥n | Prop√≥sito |
|---------|---------------|-----------|
| Dropout | 40% / 20% | Desactivaci√≥n aleatoria de neuronas |
| BatchNormalization | Por capa densa | Estabilizaci√≥n del entrenamiento |
| Label Smoothing | 0.05 | Suavizado de etiquetas para mejor generalizaci√≥n |
| Weight Decay | 1√ó10‚Åª‚Å¥ | Regularizaci√≥n L2 en pesos |
| Gradient Clipping | max_norm=1.0 | Prevenci√≥n de gradientes explosivos |
| Class Weights | Inversamente proporcional | Balanceo de clases desbalanceadas |

---

## 4. Proceso de Entrenamiento

### 4.1 Estrategia de Dos Etapas

El entrenamiento se realiz√≥ en dos etapas secuenciales, siguiendo las mejores pr√°cticas de fine-tuning para Transfer Learning:

#### Etapa 1: Entrenamiento del Head (Backbone Congelado)

| Par√°metro | Valor |
|-----------|-------|
| √âpocas | 20 (o 25% del total) |
| Learning rate | 6 √ó 10‚Åª‚Å¥ (2√ó LR base) |
| Optimizador | AdamW |
| Scheduler | Cosine Annealing |
| Early stopping patience | 10 √©pocas |
| Backbone | Congelado (requires_grad=False) |

**Objetivo:** Entrenar exclusivamente las capas del clasificador personalizado mientras el backbone EfficientNet permanece fijo, evitando la destrucci√≥n de representaciones pre-entrenadas durante la adaptaci√≥n inicial.

#### Etapa 2: Fine-Tuning Completo

| Par√°metro | Valor |
|-----------|-------|
| √âpocas | 80 (restantes) |
| Learning rate | 3 √ó 10‚Åª‚Å¥ |
| Optimizador | AdamW |
| Scheduler | Cosine Annealing (Œ∑_min = 1√ó10‚Åª‚Å∑) |
| Early stopping patience | 20 √©pocas |
| Backbone | Descongelado (requires_grad=True) |

**Objetivo:** Ajuste fino de todo el modelo, incluyendo las capas del backbone, para especializar las representaciones de caracter√≠sticas en el dominio espec√≠fico de especies Piciformes.

### 4.2 Data Augmentation

Durante el entrenamiento se aplicaron transformaciones extensivas para aumentar la variabilidad del conjunto de datos:

| Transformaci√≥n | Par√°metros | Justificaci√≥n |
|----------------|------------|---------------|
| Resize + Random Crop | 288‚Üí256 px | Variabilidad en encuadre |
| Random Rotation | ¬±30¬∞ | Orientaci√≥n variable de aves |
| Horizontal Flip | p=0.5 | Simetr√≠a bilateral |
| Vertical Flip | p=0.1 | Aves en posiciones invertidas |
| Random Resized Crop | scale=(0.85, 1.0) | Zoom variable |
| Color Jitter | brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1 | Variabilidad lum√≠nica |
| Random Affine | translate=(0.1, 0.1), scale=(0.9, 1.1) | Desplazamiento y escala |
| Gaussian Blur | kernel=3, p=0.2 | Robustez a desenfoque |
| Random Erasing | p=0.2, scale=(0.02, 0.15) | Oclusi√≥n parcial |

### 4.3 Funci√≥n de P√©rdida

Se utiliz√≥ **Cross-Entropy Loss** con las siguientes modificaciones:

```
L = CrossEntropyLoss(weight=class_weights, label_smoothing=0.05)
```

- **Class Weights:** Calculados como inversamente proporcionales a la frecuencia de cada clase, mitigando el desbalance del dataset.
- **Label Smoothing:** Factor de 0.05 para prevenir sobreconfianza en predicciones.

### 4.4 Optimizador y Scheduler

**Optimizador:** AdamW (Adam con Weight Decay desacoplado)
- Learning rate inicial: 3 √ó 10‚Åª‚Å¥
- Weight decay: 1 √ó 10‚Åª‚Å¥
- Betas: (0.9, 0.999)

**Learning Rate Scheduler:** Cosine Annealing
- T_max: n√∫mero de √©pocas de la etapa
- Œ∑_min: 1 √ó 10‚Åª‚Å∑

La estrategia de Cosine Annealing permite una reducci√≥n suave del learning rate, facilitando la convergencia a m√≠nimos m√°s estables.

---

## 5. Implementaci√≥n

### 5.1 Gesti√≥n de Datos

El script implementa una clase `SubsetDataset` que permite aplicar transformaciones diferenciadas a cada partici√≥n del dataset:

```python
class SubsetDataset(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform):
        self.dataset = dataset
        self.indices = list(indices)
        self.transform = transform
```

Esta implementaci√≥n garantiza que las transformaciones de augmentation solo se apliquen al conjunto de entrenamiento, mientras validaci√≥n y prueba utilizan √∫nicamente normalizaci√≥n.

### 5.2 Bucle de Entrenamiento

Cada √©poca ejecuta:

1. **Forward pass:** Propagaci√≥n de im√°genes a trav√©s de la red
2. **C√°lculo de p√©rdida:** Cross-Entropy con pesos de clase
3. **Backward pass:** C√°lculo de gradientes mediante autograd
4. **Gradient clipping:** Limitaci√≥n de norma m√°xima a 1.0
5. **Actualizaci√≥n de pesos:** Paso del optimizador
6. **Actualizaci√≥n del scheduler:** Ajuste del learning rate

### 5.3 Criterio de Early Stopping

El entrenamiento se detiene anticipadamente si no se observa mejora en la accuracy de validaci√≥n durante un n√∫mero consecutivo de √©pocas (patience):

- Etapa 1: patience = 10 √©pocas
- Etapa 2: patience = 20 √©pocas

El mejor modelo (seg√∫n accuracy de validaci√≥n) se guarda autom√°ticamente durante el entrenamiento.

---

## 6. Resultados

### 6.1 M√©tricas de Evaluaci√≥n

La evaluaci√≥n se realiza sobre el conjunto de prueba utilizando las siguientes m√©tricas:

| M√©trica | Descripci√≥n |
|---------|-------------|
| Accuracy | Proporci√≥n de clasificaciones correctas |
| Precision | TP / (TP + FP) por clase |
| Recall | TP / (TP + FN) por clase |
| F1-Score | Media arm√≥nica de Precision y Recall |
| Macro Average | Promedio no ponderado entre clases |
| Weighted Average | Promedio ponderado por soporte |

### 6.2 Visualizaciones Generadas

El script genera autom√°ticamente:

1. **Matriz de Confusi√≥n** (`confusion_matrix.png`): Visualizaci√≥n de predicciones vs etiquetas reales para las 13 clases.

2. **Curvas de Entrenamiento** (`training_curves.png`): Evoluci√≥n de loss y accuracy durante las √©pocas de entrenamiento.

---

## 7. Persistencia del Modelo

### 7.1 Formato PyTorch

El modelo se guarda en formato `.pt` incluyendo:

```python
{
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'val_acc': val_acc,
    'config': config
}
```

Esta estructura permite:
- Reanudar entrenamiento desde checkpoint
- Reconstruir la arquitectura exacta usando la configuraci√≥n guardada
- Acceder a m√©tricas del momento del guardado

### 7.2 Exportaci√≥n a Keras (Opcional)

El script incluye funcionalidad para exportar una arquitectura equivalente en formato Keras (`.keras`), facilitando la interoperabilidad entre frameworks.

---

## 8. Infraestructura Computacional

El entrenamiento est√° optimizado para ejecutarse en **Google Colaboratory** con los siguientes recursos:

| Componente | Especificaci√≥n |
|------------|----------------|
| GPU | NVIDIA T4 / V100 / A100 |
| Framework | PyTorch 2.x |
| CUDA | Compatible con GPU disponible |
| Workers | 2 (para DataLoader) |
| Pin Memory | Habilitado para GPU |

### 8.1 Optimizaciones de Rendimiento

- **Gradient Clipping:** Prevenci√≥n de inestabilidad num√©rica
- **Pin Memory:** Transferencia as√≠ncrona CPU‚ÜíGPU
- **Num Workers:** Carga paralela de datos
- **Mixed Precision:** Compatible (no habilitado por defecto)

---

## 9. Configuraci√≥n

### 9.1 Par√°metros por Defecto

```yaml
data:
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  image_size: 256
  num_classes: 13
  seed: 42

model:
  architecture: efficientnet_b2
  pretrained: true
  dropout_rate_1: 0.4
  dropout_rate_2: 0.2
  hidden_dim_1: 512
  hidden_dim_2: 256

training:
  batch_size: 32
  epochs: 100
  early_stopping_patience: 20
  learning_rate: 0.0003
  weight_decay: 0.0001
  optimizer: adamw
  label_smoothing: 0.05
  use_class_weights: true
  lr_schedule:
    type: cosine
    min_lr: 1e-7
```

### 9.2 Arquitecturas Soportadas

| Arquitectura | Par√°metros | Tama√±o entrada recomendado |
|--------------|------------|---------------------------|
| efficientnet_b0 | 5.3M | 224√ó224 |
| efficientnet_b2 | 9.2M | 260√ó260 |
| efficientnet_b3 | 12.0M | 300√ó300 |
| resnet50 | 25.6M | 224√ó224 |

---

## 10. Integraci√≥n con el Sistema

Este modelo se integra como segunda etapa del pipeline de clasificaci√≥n:

1. El modelo identificador determina que la imagen contiene un Piciforme
2. La imagen se redimensiona a 224√ó224 p√≠xeles (o 256√ó256 seg√∫n configuraci√≥n)
3. Se aplica normalizaci√≥n ImageNet
4. El clasificador genera probabilidades para las 13 especies
5. Se selecciona la clase con mayor probabilidad como predicci√≥n final

---

## 11. Conclusiones

El modelo de clasificaci√≥n multiclase implementa una arquitectura robusta basada en EfficientNet con m√∫ltiples t√©cnicas de regularizaci√≥n y una estrategia de entrenamiento en dos etapas. La combinaci√≥n de Transfer Learning, Data Augmentation extensivo y balanceo de clases permite obtener un clasificador generalizable para el dominio espec√≠fico de especies Piciformes.

La modularidad del c√≥digo facilita la experimentaci√≥n con diferentes arquitecturas backbone y configuraciones de hiperpar√°metros.

---

## Referencias

- Tan, M., & Le, Q. (2019). EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. *International Conference on Machine Learning (ICML)*.
- Loshchilov, I., & Hutter, F. (2019). Decoupled Weight Decay Regularization. *International Conference on Learning Representations (ICLR)*.
- M√ºller, R., Kornblith, S., & Hinton, G. (2019). When Does Label Smoothing Help? *Advances in Neural Information Processing Systems (NeurIPS)*.
- PyTorch Documentation. (2024). https://pytorch.org/docs/

---

**Documento t√©cnico - Proyecto BirdID-Piciformes**  
*Maestr√≠a en Ingenier√≠a de la Informaci√≥n (MINE) - 2025*

